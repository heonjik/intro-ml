{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zn0G3fj7o3b"
      },
      "source": [
        "# Welcome to ECE421: Introduction to Machine Learning\n",
        "\n",
        "This is your first assignment of ECE421. In this assignment, wou will\n",
        "* familiarize yourself with Google colab, NumPy, and scikitlearn\n",
        "* Implement a simple Perceptron\n",
        "* Implement linear regression\n",
        "\n",
        "This file is a Jupyter Notebook. You can double-click on section headers to show code and run each section with Shift+Enter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBO450Gc7fzq"
      },
      "source": [
        "## Setup\n",
        "\n",
        "**IMPORTANT:** You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4akJkAZfMS4e"
      },
      "source": [
        "## A little bit of practice with scikitlearn and numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oMmwfKB-GFkU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "import PerceptronImp\n",
        "import LinearRegressionImp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LlRav5sQHJWU"
      },
      "outputs": [],
      "source": [
        "# using `sklearn`, we load the *Iris dataset* and split it into a train set and\n",
        "# a test set.\n",
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train[50:], y_train[50:],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# we modify the labels into +1 and -1,\n",
        "# so that it would be suitable for binary classification.\n",
        "y_train[y_train != 1] = -1\n",
        "y_test[y_test != 1] = -1\n",
        "y_train[y_train == 1] = 1\n",
        "y_test[y_test == 1] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRi9USN_M5qa"
      },
      "source": [
        "### Investigate the dataset\n",
        "\n",
        "Let's investigate the dataset by taking a look at the shape of the training dataset and the its first datapoint.\n",
        "\n",
        "Your dataset must contain 80 datapoints in 4-dimensional space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jcRCYNBFHqLS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train is of type <class 'numpy.ndarray'>, with shape (80, 4)\n",
            "y_train is of type: <class 'numpy.ndarray'>, with shape (80,)\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "Hence, $N=80$ and $d=4$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The first datapoint:\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "$(\\underline{x}_1, y_1) = ([7.6 3.  6.6 2.1], -1)$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(f\"X_train is of type {type(X_train)}, with shape {X_train.shape}\")\n",
        "print(f\"y_train is of type: {type(y_train)}, with shape {y_train.shape}\")\n",
        "display(Markdown(rf'Hence, $N={X_train.shape[0]}$ and $d={X_train.shape[1]}$'))\n",
        "\n",
        "print(\"\\nThe first datapoint:\")\n",
        "display(Markdown(rf'$(\\underline{{x}}_1, y_1) = ({X_train[0,:]}, {y_train[0]})$'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9iaSZnwH0AE"
      },
      "source": [
        "# Part 1.1: Implementing Pocket Algorithm Using `Numpy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KYdwh3HZ5HG"
      },
      "source": [
        "## Looking into the `pred` function\n",
        "\n",
        "A Perceptron decision rule is specified by a weight vector of size (d+1)., i.e. $h_{\\underline{w}}(\\underline{x})=\\text{sign}(\\underline{w}^T\\underline{x})$, where\n",
        "\n",
        "$\\begin{align}\n",
        "\\underline{w}&=(w_0, w_1, \\ldots, w_d)\\\\\n",
        "\\underline{x}&=(x_0=1, x_1, \\ldots, x_d).\n",
        "\\end{align}$\n",
        "\n",
        "In what follows, we first generate three random datapoints with $d$ cordinates. Then augment the datapoints by adding one more cordinate which is set to 1. Next, we generate a random weight vector and use `perceptronImp.pred` function to see the predicted labels for each datapoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SttQmNznhkX1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input datapoint = \n",
            "[[ 0.49671415 -0.1382643 ]\n",
            " [ 0.64768854  1.52302986]\n",
            " [-0.23415337 -0.23413696]\n",
            " [ 1.57921282  0.76743473]]\n",
            "and their true labels = \n",
            "[-1 -1  1  1]\n",
            "\n",
            "input datapoint after augmenting = \n",
            "[[ 1.          0.49671415 -0.1382643 ]\n",
            " [ 1.          0.64768854  1.52302986]\n",
            " [ 1.         -0.23415337 -0.23413696]\n",
            " [ 1.          1.57921282  0.76743473]]\n",
            "\n",
            "weight vector = \n",
            "[-0.46947439  0.54256004 -0.46341769]\n",
            "\n",
            "Predicted labels:\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "$\\hat{y}_0 = -1$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "$\\hat{y}_1 = -1$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "$\\hat{y}_2 = -1$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "$\\hat{y}_3 = 1$"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "N, d = 4, 2\n",
        "np.random.seed(42)\n",
        "\n",
        "X = np.random.normal(size=(N, d))\n",
        "print(f\"input datapoint = \\n{X}\")\n",
        "y = np.array([-1, -1, 1, 1])\n",
        "print(f\"and their true labels = \\n{y}\")\n",
        "\n",
        "X_aug = np.hstack((np.ones(shape=(N, 1)), X))\n",
        "print(f\"\\ninput datapoint after augmenting = \\n{X_aug}\")\n",
        "\n",
        "w = np.random.normal(size=(d+1,))\n",
        "print(f\"\\nweight vector = \\n{w}\")\n",
        "\n",
        "print(\"\\nPredicted labels:\")\n",
        "for i in range(N):\n",
        "  display(Markdown(rf'$\\hat{{y}}_{i} = {PerceptronImp.pred(X_aug[i, :], w)}$'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLtHFmCfn1OH"
      },
      "source": [
        "## $E_{\\text{in}}(\\underline{w})$\n",
        "\n",
        "Now it is your turn to implement the `errorPer` function in the file `perceptronImp.py` to find the in-sample error, *i.e.*, the average number of points that are missclasified.\n",
        "\n",
        "\\\\\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `errorPer` in `perceptronImp.py`\n",
        "\n",
        "\\\\\n",
        "**NOTE:** Don't forget to consider the case of the datapoint being on the hyperplan. In this case, you should have a missclasification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AwZtT35RZhg0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test 1 result: Good Job!\n"
          ]
        }
      ],
      "source": [
        "#@title test 1\n",
        "#@markdown for the example above, your errorPer function output must be 0.25\n",
        "\n",
        "# reloding the perceptronImp module to implement your changes to the file\n",
        "reload(PerceptronImp)\n",
        "\n",
        "# for the example above, your errorPer function output must be 0.25\n",
        "if PerceptronImp.errorPer(X_aug, y, w) == 0.25:\n",
        "  print(\"test 1 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 1 result: Incorrect\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RQ0iRvLjtgNO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test 2 result: Good Job!\n"
          ]
        }
      ],
      "source": [
        "#@title test 2\n",
        "#@markdown this cell tests if you could successfully handle the case in which a point is on the hyperplane.\n",
        "\n",
        "# reloding the perceptronImp module to implement your changes to the file\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 2],\n",
        "              [1, 3]])\n",
        "\n",
        "y = np.array([1, -1])\n",
        "yp = np.array([-1, -1])\n",
        "\n",
        "w = np.array([-2, 1])\n",
        "\n",
        "# for this example, your errorPer function output must be 1. Note that the first\n",
        "# point is exactly on the hyperplane. Thus, this point must be considered as a\n",
        "# missclassification, regardless of its true label.\n",
        "if PerceptronImp.errorPer(X, y, w) == 1 and PerceptronImp.errorPer(X, yp, w) == 1:\n",
        "  print(\"test 2 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 2 result: Incorrect\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpsTRqbnx8Zy"
      },
      "source": [
        "## Fit your Perceptron\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `fit_perceptron` in `perceptronImp.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XlKSUNqixOUx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test 3 result: Good Job!\n"
          ]
        }
      ],
      "source": [
        "#@title test 3\n",
        "#@markdown this cell tests if your Perceptron can be trained over a simple mode.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[2],\n",
        "              [3]])\n",
        "y = np.array([1, -1])\n",
        "\n",
        "w = PerceptronImp.fit_perceptron(X, y)\n",
        "\n",
        "if -w[0]/w[1] < X[1, 0] and -w[0]/w[1] > X[0, 0]:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7joOQe--DYk"
      },
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `confMatrix` in `perceptronImp.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kemf0lfk4PsX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test 3 result: Good Job!\n"
          ]
        }
      ],
      "source": [
        "#@title test 4\n",
        "#@markdown this cell is simple tests for your confMatrix.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 1],\n",
        "              [1, -1],\n",
        "              [-1, 1],\n",
        "              [-1, -1]])\n",
        "y = np.array([1, 1, -1, -1])\n",
        "\n",
        "conf = PerceptronImp.confMatrix(X, y, np.array([0, 0, 1]))\n",
        "\n",
        "if np.sum(conf == np.ones(2)) == 4:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlvRT92uBPMt"
      },
      "source": [
        "# Part 1.2: Pocket Algorithm Using `scikit-learn`\n",
        "\n",
        "In this part, you will use the `scikit-learn` library to train the binary linear classification model.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `test_SciKit` in `perceptronImp.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4tUZECoE_Trm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test 3 result: Good Job!\n"
          ]
        }
      ],
      "source": [
        "#@title test 5\n",
        "#@markdown this cell tests if your scikit Perceptron works for a simple linearly separable dataset.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 1],\n",
        "              [1, -1],\n",
        "              [-1, 1],\n",
        "              [-1, -1]])\n",
        "y = np.array([1, 1, -1, -1])\n",
        "\n",
        "conf = PerceptronImp.test_SciKit(X, X, y, y)\n",
        "\n",
        "if np.sum(conf == 2*np.eye(2)) == 4:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pYRLK9EFb5z"
      },
      "source": [
        "# Comparing Your Pocket Algorithm with `scikit-learn`\n",
        "\n",
        "Let's see how your model and the one from `scikit-learn` perform with Iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hm30HlT-D4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------Test Result------------\n",
            "Confusion Matrix from Part 1a is: \n",
            " [[8 0]\n",
            " [3 9]]\n",
            "\n",
            "Confusion Matrix from Part 1b is: \n",
            " [[ 8  0]\n",
            " [ 2 10]]\n"
          ]
        }
      ],
      "source": [
        "reload(PerceptronImp)\n",
        "# Pocket algorithm using Numpy\n",
        "w = PerceptronImp.fit_perceptron(X_train, y_train)\n",
        "my_conf_mat = PerceptronImp.confMatrix(X_test, y_test, w)\n",
        "\n",
        "# Pocket algorithm using scikit-learn\n",
        "scikit_conf_mat = PerceptronImp.test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the result\n",
        "print(f\"{12*'-'}Test Result{12*'-'}\")\n",
        "print(\"Confusion Matrix from Part 1a is: \\n\", my_conf_mat)\n",
        "print(\"\\nConfusion Matrix from Part 1b is: \\n\", scikit_conf_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBN4fBYqIZMB"
      },
      "source": [
        "# Part 2.1: Linear Regression Using `NumPy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIGVCN2NJETY"
      },
      "source": [
        "## Mean Squared Error (MSE)\n",
        "\n",
        "**TODO:** edit the function `mse` to find $E_{\\text{in}}(\\underline{w})=\\frac{1}{N}||\\underline{y}-\\underline{\\hat{y}}||^2$. You find the `pred` function in `LinearRegressionImp.py` useful.\n",
        "\n",
        "functions to edit:\n",
        "* `mse` in `LinearRegressionImp.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E44XytTIKXlc"
      },
      "source": [
        "## Fit Your Model\n",
        "\n",
        "**TODO:** edit the function `mse` to find $E_{\\text{in}}(\\underline{w})=\\frac{1}{N}||\\underline{y}-\\underline{\\hat{y}}||^2$. You may find the `pred` function in `LinearRegressionImp.py` useful. Modify the function `fit_LinRegr` to implement the exact computation of the solution for linear regression\n",
        "using the NumPy library functions via the least squares method.\n",
        "\n",
        "functions to edit:\n",
        "* `mse` in `LinearRegressionImp.py`\n",
        "* `fit_LinRegr` in `LinearRegressionImp.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ID5-07FuIfWv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights:  [1.04360964e-14 2.00000000e-01 4.00000000e-01]\n",
            "NO ERROR\n"
          ]
        }
      ],
      "source": [
        "#@title test 6\n",
        "#@markdown When we input a singular matrix, the function linalg.inv often returns an error message.\n",
        "\n",
        "#@markdown In this example, we constrcuted a simple but trouble making $X$. With this X, in your fit_LinRegr(X, y) implementation, is your input to the function linalg.inv a singular\n",
        "#@markdown matrix? why?\n",
        "\n",
        "#@markdown Replacing the function `linalg.inv` with `linalg.pinv`, you should get the model’s weight and the “NO\n",
        "#@markdown ERROR” message. Explain the difference between `linalg.inv` and `linalg.pinv`.\n",
        "\n",
        "reload(LinearRegressionImp)\n",
        "\n",
        "X = np.asarray([[1, 2],\n",
        "                [2, 4],\n",
        "                [3, 6],\n",
        "                [4, 8]])\n",
        "y = np.asarray([1, 2, 3, 4])\n",
        "\n",
        "try:\n",
        "  w = LinearRegressionImp.fit_LinRegr(X, y)\n",
        "  print(\"weights: \", w)\n",
        "  print(\"NO ERROR\")\n",
        "except:\n",
        "  print(\"ERROR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU0ygOOnQPgs"
      },
      "source": [
        "# Part 2.2: Linear Regression Using `scikit-learn`\n",
        "\n",
        "In this part, you will use the `scikit-learn` library to train the linear regression model.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `test_SciKit` in `LinearRegressionImp.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST2lnmf5Q7na"
      },
      "source": [
        "# Comparing Your Linear Regression Implementation with `scikit-learn`\n",
        "\n",
        "Let's see how your model and the one from `scikit-learn` perform with diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "v1R6rPR1O6-I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean squared error from Part 2a is 2844.677138109714\n",
            "Mean squared error from Part 2b is 2844.677138109713\n"
          ]
        }
      ],
      "source": [
        "reload(LinearRegressionImp)\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, y_train = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "w = LinearRegressionImp.fit_LinRegr(X_train, y_train)\n",
        "\n",
        "#Testing Part 2a\n",
        "e = LinearRegressionImp.mse(X_test, y_test, w)\n",
        "\n",
        "#Testing Part 2b\n",
        "scikit = LinearRegressionImp.test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(f\"Mean squared error from Part 2a is {e}\")\n",
        "print(f\"Mean squared error from Part 2b is {scikit}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
